<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
        SYSTEM "https://resources.jetbrains.com/writerside/1.0/xhtml-entities.dtd">
<topic xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:noNamespaceSchemaLocation="https://resources.jetbrains.com/writerside/1.0/topic.v2.xsd"
       title="Sortieralgorithmen" id="swe-pk-algorithmen-sort">
    <show-structure for="chapter,procedure" depth="2"/>
    
    <chapter title="Einleitung" id="einleitung">
        <p>
            Ein Sortierverfahren ist ein Algorithmus, der dazu dient, Elemente einer Liste zu sortieren. Voraussetzung
            ist, dass zwischen den Elementen eine Ordnung möglich ist. Es müssen also Vorgänger- und
            Nachfolgerbeziehungen bzw. Gleichheit zwischen zwei zu vergleichenden Elementen bezüglich des
            Sortierkriteriums herstellbar sein. Diese Forderung wird als <emphasis><b>Trichotomie</b></emphasis>
            bezeichnet und sagt, dass für alle Elemente einer Menge bezüglich der Schlüssel <code>a</code>,
            <code>b</code> gilt:
        </p>

        <list>
            <li><code>a &lt; b</code> (lies: a vor b) oder</li>
            <li><code>a = b</code> oder</li>
            <li><code>a &gt; b</code> (lies: a nach b)</li>
        </list>

        <p>
            Um das mit Symbolen darzustellen, verwendet man die gezeigten Zeichen.
        </p>
        <p>
            Typische Beispiele sind die lexikografische Ordnung von Zeichenketten oder die numerische Ordnung von
            Zahlen.
        </p>
        <p>
            Eine weitere Voraussetzung dafür, dass man die Daten sortieren kann, ist
            <emphasis><b>Transitivität</b></emphasis>. Ist sie gegeben, dann ist gewährleistet, dass die Sortierung
            widerspruchsfrei durchgeführt werden kann. Es soll gelten: Gehört in der Liste Element <code>a</code> vor
            Element <code>b</code> und gehört Element <code>b</code> vor Element <code>c</code>, so folgt, dass Element
            <code>a</code> vor Element <code>c</code> anzuordnen ist.
        </p>
        <p>
            Wichtige Merkmale eines Sortier-Algorithmus sind die Zahl der durchschnittlich benötigten Schritte, bis die
            gewünschte Reihenfolge der Elemente vorliegt, und der benötigte <b>Speicherplatzbedarf</b>. Die Zahl der
            Schritte gibt die <b>Komplexität</b> des Algorithmus an und bestimmt maßgeblich, wie lange der gesamte
            Vorgang dauert.
        </p>
        <p>
            Sortierverfahren können in <b>interne</b> und <b>externe</b> Verfahren unterteilt werden. Wenn es möglich
            ist, die zu sortierenden Daten komplett im Hauptspeicher, zum Beispiel innerhalb einer Datenstruktur, zu
            sortieren, so liegt ein internes Sortierverfahren vor. Bei größeren Datenbeständen ist es nicht handhabbar,
            sämtliche Daten innerhalb des Arbeitsspeichers zu halten. Dann kommen externe Speichermedien wie Festplatten
            zum Einsatz. Die Effizienz des Algorithmus ist hier besonders wichtig, da die Lese- und Schreibzugriffe auf
            externe Medien viel Zeit beanspruchen.
        </p>
        <p>
            Unter <b>Effizienz</b> eines Suchverfahrens versteht man, wie viele Schritte im Durchschnitt notwendig sind,
            um den Sortiervorgang erfolgreich abzuschließen.
        </p>
        <p>
            Ein Sortier-Algorithmus wird als <b>stabil</b> bezeichnet, wenn er die relative Reihenfolge von Elementen
            beibehält, welche den gleichen Wert bezüglich des Sortierschlüssels aufweisen. Als <b>Sortierschlüssel</b>
            bezeichnet man das Element, nachdem die Sortierung erfolgt.
        </p>
    </chapter>

    <chapter title="Bubblesort" id="bubblesort">
        <chapter title="Grundlagen" id="bubblesort-grundlagen">
            <chapter title="Erklärung" id="bubblesort-grundlagen-erklaerung">
                <p>
                    Der Grundgedanke des Sortieralgorithmus kommt tatsächlich von Luftblasen. Ein Glas gefüllt mit
                    Mineralwasser: Darin steigen größere Luftblasen schneller auf als kleinere. Die sogenannten
                    "Bubbles" sortieren sich also der Größe nach. Deswegen kann das Sortierverfahren auch als
                    <b>"Sortieren durch Aufsteigen"</b> oder <b>"Austauschsortieren"</b> bezeichnet werden.
                </p>
                <p>
                    Der Bubble Sort gehört zu den Sortieralgorithmen mit einem vergleichsbasierten Verfahren. Dabei ist
                    das Sortierverfahren <b>stabil</b> und arbeitet <b>in-place</b>. Wegen seiner <b>durchschnittlichen
                    Zeitkomplexität von <code>O(n²)</code></b> gilt er als ziemlich langsam und wird deshalb in der
                    Praxis kaum verwendet.
                </p>
            </chapter>

            <chapter title="Prinzip" id="bubblesort-grundlagen-prinzip">
                <p>
                    Beim Bubblesort Algorithmus wird ein Array – also eine Eingabe-Liste – immer <b>paarweise von links
                    nach rechts in einer sogenannten Bubble-Phase durchlaufen</b>. Man startet also mit der ersten Zahl
                    und vergleicht diese dann mit ihrem direkten Nachbarn nach dem Sortierkriterium. Sollten beide
                    Elemente nicht in der richtigen Reihenfolge sein, werden sie ganz einfach miteinander vertauscht.
                    Danach wird direkt das nächste Paar miteinander verglichen, bis die gesamte Liste einmal durchlaufen
                    wurde. Die Phase wird so oft wiederholt, bis der gesamte Array vollständig sortiert ist.
                </p>
            </chapter>
        </chapter>

        <chapter title="Pseudocode" id="bubblesort-pseudocode">
            <code-block>
                laenge = x.Anzahl;
                for b = 1 to laenge
                    for k = 0 to (laenge-b)
                        if zahl[k] >  zahl[k+1]
                            c = zahl [k]
                            zahl[k] = zahl[k+1]
                            zahl[k+1] = c
            </code-block>
        </chapter>

        <chapter title="Bubblesort Laufzeit" id="bubblesort-laufzeit">
            <p>
                In der Praxis wird der Sortieralgorithmus kaum verwendet. Grund hierfür ist seine sehr lange Laufzeit,
                weswegen sich andere Sortierverfahren deutlich besser eignen. Beispielsweise der <b>Mergesort</b> oder
                der <b>Heapsort</b> sind bei einem Datensatz im über vierstelligem Bereich tausendmal schneller.
            </p>
            <p>
                Die Laufzeit im <b>Average-Case</b> beträgt genauso wie im <b>Worst-Case <code>O(n2)</code></b>. Das
                liegt daran, dass der Algorithmus paarweise voranschreitet und damit entsprechend viele Paare
                vergleichen muss.
            </p>
            <p>
                Nur im <b>Best-Case</b> kann er eine Laufzeit von <b><code>O(n)</code></b> erreichen. Das ist der Fall,
                wenn der Array bereits von Beginn an nach dem Sortierkriterium sortiert ist.
            </p>
            <p>
                Die Berechnung von der Anzahl benötigter Vergleiche einer Datenfolge von der Länge <code>n</code>, lässt 
                sich wie folgt darstellen:
            </p>
            
            <code-block lang="tex">
                n-1+n-2+...+1=\frac{(n(n-1)))}{2}\in O(n^{2})
            </code-block>
            
            <p>
                Bubblesort Laufzeit als Überblick:
            </p>
            
            <list>
                <li>Worst-Case: <code>O(n^2)</code></li>
                <li>Average-Case: <code>O(n^2)</code></li>
                <li>Best-Case: <code>O(n)</code></li>
            </list>
        </chapter>
    </chapter>

    <chapter title="Bucketsort" id="bucketsort">
        <chapter title="Grundlagen" id="bucketsort-grundlagen">
            <p>
                Der Bucketsort ist ein <b>nicht-vergleichsbasierter Sortieralgorithmus</b>. Er sortiert eine Liste von
                gleichmäßig verteilten Elementen sehr schnell in linearer Zeit. Das Verfahren erfolgt dabei in drei
                Schritten:
            </p>

            <list style="decimal">
                <li>
                    Zuerst erstellen wir sogenannte <b>Buckets</b>, in die wir dann die <b>Elemente</b> der unsortierten
                    Liste <b>verteilen und ablegen</b>.
                </li>
                <li>
                    Jeder einzelne dieser <b>Eimer</b> wird dann <b>mit einem weiteren Sortierverfahren</b> sortiert.
                    Diese können etwa der <b>Mergesort</b> oder der <b>Insertionsort</b>.
                </li>
                <li>
                    Der <b>Inhalt</b> der einzelnen Buckets wird dann durch eine Konkatenation <b>zu einer neuen
                    Gesamtliste zusammengefügt</b>.
                </li>
            </list>

            <p>
                Da der Sortieralgorithmus Zwischenspeicher verwendet, arbeitet das Sortierverfahren somit
                <b>out-of-place</b>.
            </p>
        </chapter>

        <chapter title="Algorithmus" id="bucketsort-algorithmus">
            <p>
                Der <b>Bucketsort Algorithmus</b> lässt sich also folgendermaßen darstellen:
            </p>

            <list style="bullet">
                <li>
                    Für den Sortiervorgang wird einerseits eine zu sortierende Liste benötigt, zusätzlich aber auch eine
                    Funktion, die jedes Element des Arrays einem Wert in dem Intervall <code>[0,n]</code> zuordnen kann.
                    Die Liste selbst setzt sich dabei aus <code>n</code>-Elementen zusammen.
                </li>
                <li>
                    Zum Sortieren werden Buckets benötigt, die das Intervall <code>[0,1]</code> in <code>n</code>
                    Teilintervalle mit der Größe <code>1/n</code> unterteilen kann. Entsprechend kann damit dann jedes
                    Element in den zugehörigen Eimer einsortiert werden. Für jeden Bucket wird dann für seine jeweiligen
                    Inhalte ein <b>Insertionsort</b> durchgeführt (Es kann auch ein <b>Mergesort</b> verwendet werden!).
                    Die Inhalte werden dann mittels Konkatenation zu einer fertig sortierten Gesamtliste zusammengefügt.
                </li>
            </list>

            <chapter title="Pseudocode" id="bucketsort-algorithmus-pseudocode">
                <code-block>
                    Bucketsort (liste, funktion)
                        n = liste.size
                        bucket = intervall(n)
                            for (element in liste)
                                bucket[floor (funktion(element) * n].add(element)
                        ausgabearray []
                        for (inhalt in buckets)
                            x.insertionsort(inhalt)
                            ausgabearray.append(x)
                        return ausgabearray
                </code-block>
            </chapter>
        </chapter>

        <chapter title="Komplexität" id="bucketsort-komplexitaet">
            <p>
                Die Komplexität hängt von mehreren Faktoren ab. Zum einen von der Verteilung der Funktionswerte. Dabei
                beträgt die <code>O</code>-Notation
            </p>

            <code-block lang="tex">
                O(n)+\sum_{n-1}^{i=0} O(l*log*l)
            </code-block>

            <p>
                Im günstigsten Fall sind die einzelnen Elemente annähernd <b>gleichverteilt</b>. Dann benötigt das
                Zuweisen in die Buckets, ebenso wie die Konkatenation eine <b>Gesamtlaufzeit</b> von <code>O(n)</code>.
                Bei anderen Werteverteilungen kann die Laufzeit jedoch vom Sortierverfahren, das für die einzelnen
                Listen verwendet wird, dominiert werden – also dem Insertionsort oder Mergesort. Die Komplexität wird
                also im Fall dieses Sortierverfahrens von verschiedenen Faktoren beeinflusst. <code>O(n)</code>
                entspricht dabei auch gleichzeitig dem Average-Case.
            </p>
            <p>
                Im Falle der Verwendung eines <b>Mergesorts</b> als angewendetes Sortierverfahren innerhalb eines
                Buckets, beträgt die Laufzeitkomplexität <code>O(n*log*n)</code>.
            </p>
            <p>
                Die <b>Speicherplatzkomplexität</b> ist <code>O(n)</code>.
            </p>
        </chapter>
    </chapter>

    <chapter title="Counting Sort" id="countingsort">
        <chapter title="Grundlagen" id="countingsort-grundlagen">
            <p>
                Die Sortiertechnik basiert dabei auf Schlüssel zwischen einem bestimmten Bereich. Dabei wird die
                <b>Anzahl der Elemente mit unterschiedlichen Schlüsselwerte gezählt</b>. Infolgedessen wird dann aus den
                Ergebnissen eine <b>sortierte Liste aufgebaut</b>.
            </p>

            <chapter title="Eigenschaften" id="countingsort-grundlagen-eigenschaften">
                <p>
                    Im Folgenden ein kurzer Überblick über die wichtigsten Eigenschaften eines Counting Sorts:
                </p>
                
                <list>
                    <li>
                        Das Verfahren gehört zu den <b>stabilen Sortieralgorithmen</b>.
                    </li>
                    <li>
                        Es handelt sich dabei um keinen vergleichsbasierter Sortieralgorithmus. Er arbeitet
                        <b>adressbasiert</b>.
                    </li>
                    <li>
                        Das Sortierverfahren zeigt sich am effizientesten, wenn der Bereich der Eingabedaten nicht
                        unmittelbar größer ist als die Anzahl der zu sortierenden Elemente. Entsprechend wird diese Form
                        der Sortierung meist <b>nur in einem mäßig großen Wertebereich verwendet</b>.
                    </li>
                    <li>
                        Die Counting Sort Laufzeitkomplexität kann allgemein mit <code>O(n)</code> inklusive einem
                        zusätzlichen Datenbereich als proportionalen Raum definiert werden.
                    </li>
                    <li>
                        Das Sortierverfahren kann <b>durch eine Erweiterung</b> auch für das <b>Sortieren von negativen
                        Zahlen</b> verwendet werden.
                    </li>
                </list>
            </chapter>
        </chapter>

        <chapter title="Funktionsweise" id="countingsort-funktionsweise">
            <p>
                Für den Algorithmus muss am Anfang eine zu sortierende <b>Eingabeliste</b> übergeben werden. Im ersten
                Schritt muss ein <b>Maximum der Zahlen</b> berechnet werden. Sollte es der Fall sein, dass es etwas
                Größeres als das Aktuelle gibt, soll dies nun das neue Größte sein. Im Anschluss soll <b>eine temporäre
                Liste in Form eines Hilfsarrays erstellt</b> werden. Im Anschluss werden dann <b>die Indizes aller
                Zahlen überprüft</b> und dadurch entsprechend <b>gezählt</b>, wie oft jede Zahl vorhanden ist. Die
                <b>Anzahl</b> wird entsprechend <b>in der temporären Liste gespeichert</b>. Jetzt geht es an die
                Sortierung, entsprechend wird die tatsächliche, <b>finale Position</b> der Zahl in der sortierten
                Reihenfolge gesucht. Beim Sortieren werden die Indizes der temporären Liste nach ihrer Anzahl geprüft.
                Dabei soll die Anzahl von <code>i</code> durchgegangen werden, um entsprechende <b>gleiche Elemente
                hintereinander einzutragen</b>. Die Zahl soll nun entsprechend in der richtigen Reihenfolge an die
                entsprechende Position eingefügt werden, um dann als <b>sortierte Liste zurückgegeben</b> zu werden.
            </p>

            <chapter title="Pseudocode" id="countingsort-funktionsweise-pseudocode">
                <code-block>
                    <![CDATA[
                    countingsort int[] zahlen
                        maximumZahlen = zahlen [0]
                        for i=1; i < zahlen.länge; i++
                            if zahlen[i] > maximumZahlen
                                maximumZahlen = zahlen [i]
                        temporäreListe = int [maximum+1]
                        for i = 0; i < zahlen.länge; i++
                            temporäreliste[zahlen[i]]++
                        finaleposition = 0;
                        for int i = 0; i <= maximum; i++
                            for int j = 0; j < temporäreliste[i]; j++
                                zahlen[finaleposition] = i
                                finaleposition++
                        return zahlen
                    ]]>
                </code-block>
            </chapter>
        </chapter>

        <chapter title="Laufzeit" id="countingsort-laufzeit">
            <p>
                Die Counting Sort Laufzeit ist immer <b>abhängig von der Anzahl der Elemente einer Liste <code>n</code>
                und der Größe des entsprechenden Zahlenintervalls <code>k</code></b>. Deshalb handelt es sich bei der
                Sortierung um einen linearen Zeitaufwand. Durch die vorhandene <code>for</code>-Schleife besitzt dabei
                jeweils <code>n</code>- oder <code>k</code>-Durchläufe. Dadurch lässt sich eine Laufzeitkomplexität von
                <code>O(n+k)</code> bestimmen. Entsprechend kann es sich für den Sortieralgorithmus vorteilhaft
                auswirken, wenn die Intervalllänge im Gegensatz zur Anzahl der Objekte <code>n</code> deutlich kleiner
                ist.
            </p>

            <chapter title="Speicherkapazität" id="countingsort-laufzeit-speicherkapazitaet">
                Dadurch, dass der Counting Sort out-of-place arbeitet, braucht der Algorithmus eine temporäre Liste/ein
                Hilfsarray zur Zwischenspeicherung unserer Zahlenwerte. Entsprechend beträgt der Speicherplatz
                <code>k</code>-Elemente, wodurch die Speicherplatzkomplexität <code>O(n+k)</code> entspricht.
            </chapter>
        </chapter>
    </chapter>

    <chapter title="Heapsort" id="heapsort">
        <chapter title="Grundlagen" id="heapsort-grundlagen">
            <p>
                Der Heapsort wurde von Robert W. Floyd und J. W. J Williams entwickelt. Er gehört zu den <b>instabilen
                Sortieralgorithmen</b>, arbeitet dabei aber nach dem <b>in-place</b>-Prinzip. Die Funktionsweise basiert
                eigentlich hauptsächlich auf <b>binären Heap Eigenschaften</b> als zentrale Datenstruktur und ist dabei
                ein <b>fast vollständiger binärer Baum</b>. Die Knoten enthalten dann die Daten, die letztendlich
                sortieren werden sollen.
            </p>
            <p>
                Das <b>Sortierverfahren</b> hat eine Zeitkomplexität von <code>O(n log(n))</code>, damit gibt es keinen
                asymptotisch schnelleren <b>Sortieralgorithmus</b> der vergleichsbasiert ist. Man kann ihn im
                Allgemeinen durch seine Vorgehensweise auch als Verbesserung zum <b>Selectionsort</b> verstehen.
            </p>
        </chapter>

        <chapter title="Funktionsweise" id="heapsort-funktionsweise">
            <p>
                Als erstes benötigt es eine Liste, die nach dem Heap Sort geordnet werden soll, in diesem Fall nach dem
                Max-Heap – also von klein nach groß. Im nächsten Schritt muss also aus dem Array ein max-Heap gebaut
                werden (<b>Build-Max-Heap</b>). Dann kommt auch schon der Hauptteil, welcher unterschiedlich benannt
                werden kann. Bekannt als: <b>Heapyfy, Downheap, Versickern</b> oder eventuell auch <b>Versenken</b>.
                Diese Prozedur beschreibt eine Prüfung der Heap-Bedingung bezüglich der Kinder mit ihrem jeweiligen
                Vater. Wenn die Heap-Bedingung nicht erfüllt ist, muss das größere Kind mit dem Vater ausgetauscht
                werden. Dies wird so oft wiederholt, bis die Heap-Size 1 ist, also nur noch ein "unsortiertes" Element
                besteht.
            </p>

            <chapter title="Pseudocode" id="heapsort-funktionsweise-pseudocode">
                <code-block>
                    <![CDATA[
                    Heapsort(arr) {
                        BuildMaxHeap(arr)
                        for i
                            tausche arr[1]  arr[i]
                            heapsize
                            Versickern(arr, 1)
                    }

                    BuildMaxHeap(arr) {
                        heapsize
                        for i
                            Versickern(arr, i)
                    }

                    Versickern(arr, i) {
                        l
                        r
                        if (l<=heapsize) and (arr[l]>arr[i])
                            largest
                        else
                            largest
                        if (r<=heapsize) and (arr[r]>arr[largest])
                            largest
                        if (largest != i) {
                            tausche arr[i]  arr[largest]
                            Versickern(arr, largest)
                        }
                    }
                    ]]>
                </code-block>
            </chapter>
        </chapter>

        <chapter title="Komplexität" id="heapsort-komplexitaet">
            <p>
                Die Heapsort Komplexität beträgt im Allgemeinen <code>O(nlog(n))</code> Vergleiche. Damit ist er
                bezüglich vergleichsbasierten-Sortieralgorithmen das schnellste asymptotische Sortierverfahren. Jedoch
                kann er trotzdem beispielsweise mit dem <b>Quicksort</b> in seiner standardisierten Form nicht
                mithalten. Da der Heapsort in <b>verschiedenen Prozeduren</b> abläuft, kann für jedes <b>eine eigene
                Laufzeitkomplexität</b> festgestellt werden. Der <b>downheap</b> benötigt beispielsweise
                <b><code>log(n)</code></b> Schritte beim Vergleichen. Der <b>buildheap</b> zeigt bei einer genaueren
                Analyse auf, dass er nur <code>O(n)</code> Vergleiche braucht.
            </p>
            <p>
                Wenn man sich die potenziellen Fälle genauer ansieht, kann gesagt werden, dass die Heapsort Laufzeit
                sowohl im <b>Worst Case</b>, als auch im <b>Average Case</b> und <b>Best Case</b>
                <code>O(nlog(n))</code> beträgt. Grund dafür ist, dass der Heap-Aufbau eine schrittweise vollständige
                Invertierung der Sortierreihenfolge benötigt.
            </p>
        </chapter>

        <chapter title="Varianten" id="heapsort-varianten">
            <p>
                Für den Heapsort gibt es <b>verschiedene Varianten</b>. Neben dem Standard-Heapsort gibt es noch den
                <b>Bottom-Up-Heapsort</b>, den <b>Smoothsort</b>, die <b>Ternären Heaps</b> und die <b>n-äre Heaps</b>,
                welche die Komplexität in verschiedenen Bereichen potenziell steigern können.
            </p>

            <chapter title="Bottom-Up-Heapsort" id="heapsort-varianten-bottomupheapsort">
                <p>
                    Die dabei populärste Variante ist der Bottom-Up-Heapsort, da er oft nur die Hälfte an
                    Vergleichsoperationen benötigt und kommt damit der Laufzeit des Quicksort sehr Nahe. Aber wie
                    funktioniert das? Da ein Binärbaum größtenteils aus Blättern besteht und sich durch das Sortieren
                    die niedrigeren Werte bereits abgesenkt werden mussten, arbeitet die Variante mit der Annahme, dass
                    ein Element bis zur Blattebene oder in der Nähe versickert werden muss. Entsprechend wird auf
                    Verdacht bis zur Blattebene abgesenkt und auf den zweiten Vergleich verzichtet. Der
                    Bottom-Up-Heapsort sollte aber nicht bei kleineren Feldern mit einfacher numerischer
                    Vergleichsoperation benutzt werden oder sehr viele Elemente gleichwertig sind. Heißt also, man
                    sollte ihn vor allem bei großen Datenmengen mit hohem Aufwand pro Vergleichsoperationen verwenden.
                </p>
            </chapter>

            <chapter title="Smoothsort" id="heapsort-varianten-smoothsort">
                <p>
                    Der Smoothsort ändert die Reihenfolge der Vorgehensweise. Während normalerweise vorsortierte Felder
                    keinen Vorteil erbringen, da immer das größte Element an die Wurzel wandern muss, um die Zahl
                    anschließend wieder mit dem letzten Knoten austauscht, arbeitet der Smoothsort direkt umgekehrt.
                    Jedoch ist bei der Umsetzung die Gewährleistung des Heapstatus beim Sortieren sehr aufwändig.
                </p>
            </chapter>

            <chapter title="Ternäre Heaps" id="heapsort-varianten-ternaereheaps">
                <p>
                    Wie man sich vielleicht schon denken kann, werden hier statt binären Heaps, ternäre Heaps benutzt.
                    Entsprechend läuft er nicht auf Basis eines Binärbaums, sondern ein vollständig besetzter Knoten hat
                    jeweils 3 Kinder. Dadurch können die Vergleichsoperationen reduziert werden. Beispielsweise bei sehr
                    großen Feldern, die mehrere Millionen Elemente enthalten, kann dabei 20-30 % der Vergleiche
                    eingespart werden, wenn man sich das gleiche aber bei kleineren Feldern ansieht, kann es sogar sein,
                    dass der Sortieralgorithmus dadurch langsamer als der Standard-Heapsort ist.
                </p>
            </chapter>

            <chapter title="n-äre Heaps" id="heapsort-varianten-naereheaps">
                <p>
                    Wie schon bei den Ternären Heaps, kann der Baum natürlich noch breiter, bzw. die Heaps noch flacher
                    gestaltet werden, durch das <b>Erweitern der Anzahl von Kindern eines Vaters</b>. Dadurch steigt die
                    Anzahl der Vergleichsoperationen zwar weiter an, jedoch können dadurch andere Vorteile bezüglich der
                    Effizienz von Caches geschaffen werden, da der sonstige Aufwand weiter gesenkt werden kann und
                    geordneter auf die Elemente zugegriffen werden kann.
                </p>
            </chapter>
        </chapter>
    </chapter>

    <chapter title="Insertionsort" id="insertionsort">
        <chapter title="Grundlagen" id="insertionsort-grundlagen">
            <p>
                Der Insertion Sort gehört zu den stabilen <b>Sortieralgorithmen</b> und kann als <b>Sortieren durch
                Einfügen</b> beschrieben werden, deswegen auch <b>Einfügesortierenmethode</b> genannt. Das Ganze lässt
                sich einfach durch die englischen Wörter insertion = Einfügen und sort = sortieren ableiten, weswegen
                der Sortieralgorithmus auch manchmal als <b>Insertsort</b> bezeichnet wird. Allgemein kann auch noch
                gesagt werden, dass der Sortieralgorithmus einfach zu implementieren ist und dabei bei kleiner <b>oder
                schon teilweise vorsortierten Eingabemengen sehr effizient</b> arbeitet. Da das Sortierverfahren keinen
                zusätzlichen Speicherplatz benötigt, arbeitet der Algorithmus <b>in-place</b>, was natürlich für seine
                Speicherplatzkomplexität spricht.
            </p>

            <chapter title="Prinzip" id="insertionsort-grundlagen-prinzip">
                <p>
                    Der <b>Grundgedanke</b> ist eigentlich ganz einfach, da es wahrscheinlich dem am nächsten kommt, wie
                    man die Zahlen selbst ordnen würde. Dabei stellt man sich ein Kartenspiel vor, welches der Größe
                    nach sortiert werden soll. In deiner Hand liegt die Karte Pik 5 und Pik 9. Als Nächstes wird die Pik
                    6 gezogen. Diese Karte wird in der Mitte zwischen den beiden anderen eingeordnet. Genau so geht der
                    Insertionsort auch vor.
                </p>
                <p>
                    Der Insertionsort durchläuft Schritt für Schritt einen Array und <b>entnimmt</b> dabei aus der
                    <b>unsortierten Eingabefolge ein Element</b> und <b>setzt</b> es dann an der entsprechend
                    <b>richtigen Stelle wieder ein</b> – „Sortieren durch Einfügen“. Die <b>restlichen Elemente</b> des
                    Arrays müssen dann wiederum <b>hinter dem neu eingefügten Wert verschoben</b> werden.
                </p>
            </chapter>
        </chapter>

        <chapter title="Algorithmus" id="insertionsort-algorithmus">

            <chapter title="Pseudocode" id="insertionsort-algorithmus-pseudocode">

            </chapter>
        </chapter>

        <chapter title="Laufzeit" id="insertionsort-laufzeit">

            <chapter title="Komplexität" id="insertionsort-laufzeit-komplexität">

            </chapter>
        </chapter>
    </chapter>

    <chapter title="Quellen" id="quellen">
        <tip>
            <b>(BUCH)</b>
            978-3836244763, "Handbuch für Softwareentwickler", Veikko Krypczyk &amp; Elena Bochkor, 2018
        </tip>
        <tip>
            <b>(WEBSEITE)</b>
            <a href="https://studyflix.de/informatik/bubblesort-1325" ignore-vars="true">
                https://studyflix.de/informatik/bubblesort-1325
            </a>, 2020-12-18 14:40
        </tip>
        <tip>
            <b>(WEBSEITE)</b>
            <a href="https://studyflix.de/informatik/bucketsort-1438" ignore-vars="true">
                https://studyflix.de/informatik/bucketsort-1438
            </a>, 2020-12-18 15:50
        </tip>
        <tip>
            <b>(WEBSEITE)</b>
            <a href="https://studyflix.de/informatik/counting-sort-1407" ignore-vars="true">
                https://studyflix.de/informatik/counting-sort-1407
            </a>, 2020-12-18 16:00
        </tip>
        <tip>
            <b>(WEBSEITE)</b>
            <a href="https://studyflix.de/informatik/heapsort-1326" ignore-vars="true">
                https://studyflix.de/informatik/heapsort-1326
            </a>, 2020-12-18 16:10
        </tip>
        <tip>
            <b>(WEBSEITE)</b>
            <a href="https://studyflix.de/informatik/insertionsort-1321" ignore-vars="true">
                https://studyflix.de/informatik/insertionsort-1321
            </a>, 2020-12-18 14:45
        </tip>
    </chapter>
</topic>